{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predicting spam emails.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cecilia-wanja/Prediction-of-the-people-who-were-likely-to-survive-in-the-Titanic/blob/master/Predicting_spam_emails.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDPUw4a2y6td",
        "colab_type": "text"
      },
      "source": [
        "***Question***\n",
        "\n",
        "Predicting whether or not an email is spam or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss3eAbcvzjIB",
        "colab_type": "text"
      },
      "source": [
        "***Background Information***\n",
        "\n",
        "Our collection of spam e-mails came from our postmaster and individuals who had filed spam. Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam.\n",
        "\n",
        "The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_QgceFhzTs-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CcdXF5dj8ZP",
        "colab_type": "code",
        "outputId": "cb6d8ce5-6ab6-48da-e0bd-a2b53d1f17f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#importing the necessary libraries\n",
        "import pandas as pd\n",
        "\n",
        "#previewing our dataset\n",
        "data = pd.read_csv('/content/spambase_csv.csv')\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_%3B</th>\n",
              "      <th>char_freq_%28</th>\n",
              "      <th>char_freq_%5B</th>\n",
              "      <th>char_freq_%21</th>\n",
              "      <th>char_freq_%24</th>\n",
              "      <th>char_freq_%23</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1.93</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.28</td>\n",
              "      <td>3.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.36</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.16</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   word_freq_make  word_freq_address  ...  capital_run_length_total  class\n",
              "0            0.00               0.64  ...                       278      1\n",
              "1            0.21               0.28  ...                      1028      1\n",
              "2            0.06               0.00  ...                      2259      1\n",
              "3            0.00               0.00  ...                       191      1\n",
              "4            0.00               0.00  ...                       191      1\n",
              "\n",
              "[5 rows x 58 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdry40zekbHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x= data.iloc[:,:48].values\n",
        "\n",
        "y=data.iloc[:,-1].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZthBsROFlAx4",
        "colab_type": "code",
        "outputId": "a9ba6e8a-1b27-4ea5-89d2-c9de263d5df0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.reshape(-1, 1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.  ],\n",
              "       [0.64],\n",
              "       [0.64],\n",
              "       ...,\n",
              "       [0.65],\n",
              "       [0.  ],\n",
              "       [0.  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-8rtQRxlFkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the different naive bayes classifiers\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB, BernoulliNB"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs2m8tk5lLkW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#defining the three models of naive bayes that we are going to use.\n",
        "gau = GaussianNB()\n",
        "multi = MultinomialNB()\n",
        "bern = BernoulliNB()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXxUyWs0lRFe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dividing our dataset into training and test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqNfG7Y5lVCD",
        "colab_type": "code",
        "outputId": "37d1b641-50ef-485b-9776-b05dcdd20575",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#training using the models above\n",
        "gau.fit(x_train, y_train)\n",
        "multi.fit(x_train, y_train)\n",
        "bern.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeHQT2aom-QG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#predicting the outcome\n",
        "y_pred1 = gau.predict(x_test)\n",
        "y_pred2 = multi.predict(x_test)\n",
        "y_pred3 = bern.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRlMlIIflfUm",
        "colab_type": "code",
        "outputId": "073f4906-7029-4df3-bd41-43e1303987b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#evaluating the model\n",
        "\n",
        "#importing the necessary libraries\n",
        "from sklearn import metrics\n",
        "\n",
        "#model accuracy\n",
        "print('Accuracy of Gaussian:', metrics.accuracy_score(y_test,y_pred1)*100)\n",
        "print('\\n')\n",
        "\n",
        "print('Accuracy of Multinomial:', metrics.accuracy_score(y_test,y_pred2)*100)\n",
        "print('\\n')\n",
        "\n",
        "print('Accuracy of Bernoulli:', metrics.accuracy_score(y_test,y_pred3)*100)\n",
        "print('\\n')\n",
        "\n",
        "#classification report of each\n",
        "print('Classification report of Gaussian:',)\n",
        "print(metrics.classification_report(y_test,y_pred1))\n",
        "print('\\n')\n",
        "\n",
        "print('Classification report of Multinomial:',) \n",
        "print(metrics.classification_report(y_test,y_pred2))\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "print('Classification report of Bernoulli:',)\n",
        "print(metrics.classification_report(y_test,y_pred3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of Gaussian: 79.58740499457112\n",
            "\n",
            "\n",
            "Accuracy of Multinomial: 87.07926167209556\n",
            "\n",
            "\n",
            "Accuracy of Bernoulli: 86.53637350705755\n",
            "\n",
            "\n",
            "Classification report of Gaussian:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.70      0.80       538\n",
            "           1       0.69      0.92      0.79       383\n",
            "\n",
            "    accuracy                           0.80       921\n",
            "   macro avg       0.81      0.81      0.80       921\n",
            "weighted avg       0.83      0.80      0.80       921\n",
            "\n",
            "\n",
            "\n",
            "Classification report of Multinomial:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.83      0.88       538\n",
            "           1       0.79      0.93      0.86       383\n",
            "\n",
            "    accuracy                           0.87       921\n",
            "   macro avg       0.87      0.88      0.87       921\n",
            "weighted avg       0.88      0.87      0.87       921\n",
            "\n",
            "\n",
            "\n",
            "Classification report of Bernoulli:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.91      0.89       538\n",
            "           1       0.86      0.81      0.83       383\n",
            "\n",
            "    accuracy                           0.87       921\n",
            "   macro avg       0.86      0.86      0.86       921\n",
            "weighted avg       0.87      0.87      0.86       921\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJzfFlzVpPXV",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameter tuning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oghcggsgq7tS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Multinomial Naive Bayes model parameter tuning\n",
        "model = MultinomialNB()\n",
        "param_grid = {'alpha': [1.0, 2.0, 3.0, 4.0, 5.0]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66E-R2c0nOxK",
        "colab_type": "code",
        "outputId": "c9be659e-15a1-4d67-f870-6d72f9f337c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Hyper parameter Tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print('Hyper Parameter Tuning')\n",
        "grid = GridSearchCV(estimator = multi, param_grid = param_grid, cv = 5)\n",
        "\n",
        "grid.fit(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hyper Parameter Tuning\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
              "                                     fit_prior=True),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'alpha': [1.0, 2.0, 3.0, 4.0, 5.0]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYAFeuP4qlnf",
        "colab_type": "code",
        "outputId": "6fc55c33-7bce-4908-c837-73838b12778c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Results returned by GridSearchCV\\n\")\n",
        "print(\"Best estimator: \", grid.best_estimator_)\n",
        "print(\"\\n\")\n",
        "print(\"Best score: \", grid.best_score_)\n",
        "print(\"\\n\")\n",
        "print(\"Best parameters found: \", grid.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results returned by GridSearchCV\n",
            "\n",
            "Best estimator:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "\n",
            "\n",
            "Best score:  0.8698369565217391\n",
            "\n",
            "\n",
            "Best parameters found:  {'alpha': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qB-VhKyrKwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "multi = MultinomialNB()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPnVaDhqt28s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#dividing our dataset into training and test set\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.4,random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQNUxNs8uCRS",
        "colab_type": "code",
        "outputId": "bd745001-0b4d-4fbe-f1a1-144565f3bb41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "multi.fit(x_train, y_train)\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M06fjG67uF6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred2 = multi.predict(x_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM5G6LQwuLrz",
        "colab_type": "code",
        "outputId": "970a5ef1-64c6-4040-854c-a3ffa8f7d92b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print('Classification report of Multinomial:')\n",
        "print(metrics.classification_report(y_test,y_pred2))\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Classification report of Multinomial:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.83      0.88      1097\n",
            "           1       0.79      0.93      0.85       744\n",
            "\n",
            "    accuracy                           0.87      1841\n",
            "   macro avg       0.87      0.88      0.87      1841\n",
            "weighted avg       0.88      0.87      0.87      1841\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1HGU1to5KzU",
        "colab_type": "text"
      },
      "source": [
        "***Conclusion and Recommendation***\n",
        "\n",
        "As the test_size increased, there was no trend in the way the accuracy_score changed. Hence the test_size is not an accuracy_score factor.\n",
        "\n",
        "The best Estimator for this dataset was MultiNomial according to the best estimator function.\n",
        "\n",
        "On the other hand, hyperparameter tuning did not make a significant difference in the prediction of the model.Instead it reduces it by 1%.\n",
        "\n",
        "The precision of our 'not spam' dataset was 0.95 which means that the measurement is very precise.The precision of our spam dataset is 0.79 which is not very good. Hence our model will mostly recognize a 'not spam' email as compared to a spam email."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO7P4MVcuS1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}